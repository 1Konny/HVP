{
  "train_batch_size": 1,
  "gradient_accumulation_steps": 1,
  "steps_per_print": 10000,
  "optimizer": {
    "type": "Adam",
    "params": {
      "lr": 0.0001,
      "betas": [
         0.9,
         0.999
       ]
    }
  }
}
